# Human-in-the-loop Protocol

Humans do two things:
1) agree on the rubric (what matters)
2) review sampled results + add qualitative feedback

Recommended workflow:
- define rubric with stakeholders
- run bulk eval
- sample cases (random by topic)
- review:
  - pass/fail correctness of judge
  - label failure modes + notes
- feed back into:
  - rubric clarifications
  - product changes
  - guardrail changes
